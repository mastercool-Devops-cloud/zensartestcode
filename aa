
Flipkart is one of the most popular web portals that allows users to place online purchase order for books, mobiles & cars. Please find below the purchase order details:
Order Type
Order Details
Book purchase
id, book title, book author, price, order placement date, customer name, customer email, customer mobile
Mobile purchase
id, mobile vendor, model, price, order placement date, customer name, customer email, customer mobile
Car purchase
Id, car vendor, model, color, price, order placement date, customer name, customer email, customer mobile
The order processing is different for every order type. Hence, we need separate order processor for each order type.
Solution:
Solution:
1. Create a Kafka cluster with a topic ‘FlipkartOrdersTopic’ having separate partition for each order type. Make sure you keep at least one replica of every partition so that failure scenario can be handled.
2. Purchase order producer is continuously pushing orders into the topic & depending upon the order type, the message should automatically route to respective partition. Here, you need to write custom serializer & custom partitioner.
3. Create a consumer group having 3 consumers each one is consuming messages from the respective partition. You need to log all orders on console to prove that every consumer is consuming orders from respective order type only.
4. Write a Kafka Streams program that continuously reads orders & displays report of number of orders & total transaction amount against every order type. i.e. “Books_order_count”: 230, “Books_total_transaction_amount”: 2500000, “Mobiles_order_count”: 410, “Mobiles_total_transaction_amount”: 9000000,
“Cars_order_count”: 57, “Cars_total_transaction_amount”: 65400000,

----------------------------------------------------------------
//create 3 threads for each order type. Every thread dynamically creates random order & pushes to the topic.
		//Every type of order is having different message key (flipkart.car.order, flipkart.mobile.order, flipkart.book.order)
		
		//Use ExecutorService to create thread pool having at least 3 threads.

//write a code that generates car orders & send to the 'OrderTopic'

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;

import java.util.Properties;
import java.util.Random;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;

public class OrderProducer {

    private static final String TOPIC = "order_topic";
    private static final Random RANDOM = new Random();

    public static void main(String[] args) {
        // Create Kafka producer configuration
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        KafkaProducer<String, String> producer = new KafkaProducer<>(props);

        // Create an ExecutorService with a thread pool of 3 threads
        ExecutorService executorService = Executors.newFixedThreadPool(3);

        // Submit tasks for each order type
        executorService.submit(() -> generateOrders(producer, "flipkart.car.order"));
        executorService.submit(() -> generateOrders(producer, "flipkart.mobile.order"));
        executorService.submit(() -> generateOrders(producer, "flipkart.book.order"));

        // Shutdown the executor service after some time
        executorService.shutdown();
        try {
            executorService.awaitTermination(10, TimeUnit.SECONDS);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }

        // Close the producer
        producer.close();
    }

    private static void generateOrders(KafkaProducer<String, String> producer, String messageKey) {
        for (int i = 0; i < 10; i++) { // Generating 10 orders dynamically for each order type
            String order = createRandomOrder(messageKey);
            ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC, messageKey, order);

            // Send the message asynchronously
            Future<RecordMetadata> future = producer.send(record, (metadata, exception) -> {
                if (exception != null) {
                    System.err.println("Error producing to topic: " + exception.getMessage());
                } else {
                    System.out.printf("Produced record to topic %s partition [%d] @ offset %d with key %s\n",
                            metadata.topic(), metadata.partition(), metadata.offset(), messageKey);
                }
            });

            try {
                future.get(); // Wait for the result of the send
            } catch (Exception e) {
                e.printStackTrace();
            }

            // Sleep for a short time to simulate dynamic order creation
            try {
                Thread.sleep(500);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }

    // Simulate creating a random order for the given order type
    private static String createRandomOrder(String orderType) {
        int orderId = RANDOM.nextInt(1000);
        return String.format("{\"orderId\": %d, \"orderType\": \"%s\", \"details\": \"Order details for %s\"}",
                orderId, orderType, orderType);
    }
}

----------------------------------------------------------------
Order producer produces orders. Write the processor that filters orders having price>=100.
Note: create 2 topics OrderPriceTopic & HighPriceOrdersTopic. Producer & Consumer code already attached. You need to write only processor. Please use kstream.filter(xx) method.

-------------------------------------------------------------------
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;
import java.util.Random;
import java.util.concurrent.*;

public class MultiProducerOrderApp {

    // Kafka Producer creation method for each order type
    private static Producer<String, String> createProducer() {
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("key.serializer", StringSerializer.class.getName());
        props.put("value.serializer", StringSerializer.class.getName());
        return new KafkaProducer<>(props);
    }

    // Callable task to generate car orders
    static class GenerateCarOrdersTask implements Callable<String> {
        private final Producer<String, String> carProducer;

        public GenerateCarOrdersTask(Producer<String, String> carProducer) {
            this.carProducer = carProducer;
        }

        @Override
        public String call() {
            Random random = new Random();
            try {
                String carOrder = "CarOrderID-" + random.nextInt(1000) + ", Model-" +
                        random.nextInt(10) + ", Price-" + random.nextInt(50000);
                ProducerRecord<String, String> record = new ProducerRecord<>("OrderTopic", "flipkart.car.order", carOrder);
                RecordMetadata metadata = carProducer.send(record).get();
                return "Car order sent to partition " + metadata.partition() + " with offset " + metadata.offset();
            } catch (Exception e) {
                e.printStackTrace();
                return "Failed to send car order";
            }
        }
    }

    // Callable task to generate mobile orders
    static class GenerateMobileOrdersTask implements Callable<String> {
        private final Producer<String, String> mobileProducer;

        public GenerateMobileOrdersTask(Producer<String, String> mobileProducer) {
            this.mobileProducer = mobileProducer;
        }

        @Override
        public String call() {
            Random random = new Random();
            try {
                String mobileOrder = "MobileOrderID-" + random.nextInt(1000) + ", Model-" +
                        random.nextInt(10) + ", Price-" + random.nextInt(10000);
                ProducerRecord<String, String> record = new ProducerRecord<>("OrderTopic", "flipkart.mobile.order", mobileOrder);
                RecordMetadata metadata = mobileProducer.send(record).get();
                return "Mobile order sent to partition " + metadata.partition() + " with offset " + metadata.offset();
            } catch (Exception e) {
                e.printStackTrace();
                return "Failed to send mobile order";
            }
        }
    }

    // Callable task to generate book orders
    static class GenerateBookOrdersTask implements Callable<String> {
        private final Producer<String, String> bookProducer;

        public GenerateBookOrdersTask(Producer<String, String> bookProducer) {
            this.bookProducer = bookProducer;
        }

        @Override
        public String call() {
            Random random = new Random();
            try {
                String bookOrder = "BookOrderID-" + random.nextInt(1000) + ", Title-" +
                        "Book " + random.nextInt(50) + ", Price-" + random.nextInt(500);
                ProducerRecord<String, String> record = new ProducerRecord<>("OrderTopic", "flipkart.book.order", bookOrder);
                RecordMetadata metadata = bookProducer.send(record).get();
                return "Book order sent to partition " + metadata.partition() + " with offset " + metadata.offset();
            } catch (Exception e) {
                e.printStackTrace();
                return "Failed to send book order";
            }
        }
    }

    public static void main(String[] args) {
        // Create producers for each order type
        Producer<String, String> carProducer = createProducer();
        Producer<String, String> mobileProducer = createProducer();
        Producer<String, String> bookProducer = createProducer();

        // Create a thread pool with at least 3 threads
        ExecutorService executorService = Executors.newFixedThreadPool(3);

        // Create tasks for each order type
        GenerateCarOrdersTask generateCarOrdersTask = new GenerateCarOrdersTask(carProducer);
        GenerateMobileOrdersTask generateMobileOrdersTask = new GenerateMobileOrdersTask(mobileProducer);
        GenerateBookOrdersTask generateBookOrdersTask = new GenerateBookOrdersTask(bookProducer);

        // Submit tasks to the executor service
        Future<String> carOrderResult = executorService.submit(generateCarOrdersTask);
        Future<String> mobileOrderResult = executorService.submit(generateMobileOrdersTask);
        Future<String> bookOrderResult = executorService.submit(generateBookOrdersTask);

        try {
            // Retrieve and print results of the tasks
            System.out.println(carOrderResult.get());
            System.out.println(mobileOrderResult.get());
            System.out.println(bookOrderResult.get());
        } catch (InterruptedException | ExecutionException e) {
            e.printStackTrace();
        } finally {
            // Shutdown the executor service and close producers
            executorService.shutdown();
            carProducer.close();
            mobileProducer.close();
            bookProducer.close();
        }
    }
}

-----------------------------------------------------------------------------
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.serialization.StringDeserializer;

import java.time.Duration;
import java.util.Collections;
import java.util.Properties;
import java.util.concurrent.Callable;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;

public class OrderConsumerGroupUsingCallable {

    private static final String TOPIC = "OrderTopic";
    private static final String GROUP_ID = "orderConsumerGroup";
    private static final String BOOTSTRAP_SERVERS = "localhost:9092";

    // Create Kafka Consumer configuration
    private static KafkaConsumer<String, String> createConsumer(String groupId) {
        Properties props = new Properties();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
        props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");

        return new KafkaConsumer<>(props);
    }

    // Callable task to consume Car orders
    static class CarOrderConsumerTask implements Callable<String> {
        private final KafkaConsumer<String, String> consumer;

        public CarOrderConsumerTask(KafkaConsumer<String, String> consumer) {
            this.consumer = consumer;
        }

        @Override
        public String call() {
            try {
                // Assign the consumer to partition 0 for car orders
                TopicPartition carOrderPartition = new TopicPartition(TOPIC, 0);
                consumer.assign(Collections.singletonList(carOrderPartition));

                while (true) {
                    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
                    for (ConsumerRecord<String, String> record : records) {
                        System.out.println("Car Order: " + record.value());
                    }
                }
            } finally {
                consumer.close();
            }
        }
    }

    // Callable task to consume Mobile orders
    static class MobileOrderConsumerTask implements Callable<String> {
        private final KafkaConsumer<String, String> consumer;

        public MobileOrderConsumerTask(KafkaConsumer<String, String> consumer) {
            this.consumer = consumer;
        }

        @Override
        public String call() {
            try {
                // Assign the consumer to partition 1 for mobile orders
                TopicPartition mobileOrderPartition = new TopicPartition(TOPIC, 1);
                consumer.assign(Collections.singletonList(mobileOrderPartition));

                while (true) {
                    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
                    for (ConsumerRecord<String, String> record : records) {
                        System.out.println("Mobile Order: " + record.value());
                    }
                }
            } finally {
                consumer.close();
            }
        }
    }

    // Callable task to consume Book orders
    static class BookOrderConsumerTask implements Callable<String> {
        private final KafkaConsumer<String, String> consumer;

        public BookOrderConsumerTask(KafkaConsumer<String, String> consumer) {
            this.consumer = consumer;
        }

        @Override
        public String call() {
            try {
                // Assign the consumer to partition 2 for book orders
                TopicPartition bookOrderPartition = new TopicPartition(TOPIC, 2);
                consumer.assign(Collections.singletonList(bookOrderPartition));

                while (true) {
                    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
                    for (ConsumerRecord<String, String> record : records) {
                        System.out.println("Book Order: " + record.value());
                    }
                }
            } finally {
                consumer.close();
            }
        }
    }

    public static void main(String[] args) throws Exception {
        // Create a thread pool with 3 threads
        ExecutorService executorService = Executors.newFixedThreadPool(3);

        // Create consumers for each order type
        KafkaConsumer<String, String> carConsumer = createConsumer(GROUP_ID);
        KafkaConsumer<String, String> mobileConsumer = createConsumer(GROUP_ID);
        KafkaConsumer<String, String> bookConsumer = createConsumer(GROUP_ID);

        // Create Callable tasks for each order type
        CarOrderConsumerTask carTask = new CarOrderConsumerTask(carConsumer);
        MobileOrderConsumerTask mobileTask = new MobileOrderConsumerTask(mobileConsumer);
        BookOrderConsumerTask bookTask = new BookOrderConsumerTask(bookConsumer);

        // Submit the tasks to the ExecutorService
        Future<String> carResult = executorService.submit(carTask);
        Future<String> mobileResult = executorService.submit(mobileTask);
        Future<String> bookResult = executorService.submit(bookTask);

        // Keep the executor service running indefinitely (or handle future results if needed)
        // This code will block, and consumers will keep consuming messages until manually terminated
    }
}
------------------------------------------------------
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.kstream.KStream;
import org.apache.kafka.streams.kstream.KTable;
import org.apache.kafka.streams.kstream.Materialized;
import org.apache.kafka.streams.kstream.Produced;
import org.apache.kafka.streams.kstream.Aggregator;
import org.apache.kafka.streams.kstream.Initializer;

import java.util.Properties;

public class OrderAggregator {

    public static void main(String[] args) {
        // Kafka Streams Configuration
        Properties props = new Properties();
        props.put(StreamsConfig.APPLICATION_ID_CONFIG, "order-aggregator-app");
        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass().getName());
        props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass().getName());

        StreamsBuilder builder = new StreamsBuilder();

        // Stream from the OrderTopic
        KStream<String, String> orderStream = builder.stream("OrderTopic");

        // Aggregating the results for each order type
        KTable<String, OrderAggregate> aggregateTable = orderStream
            .groupByKey() // Group by the key (order type: car, mobile, book)
            .aggregate(
                // Initialize aggregator
                OrderAggregator::newOrderAggregate,
                // Aggregation logic (order count and total transaction amount)
                (key, value, aggregate) -> {
                    OrderDto orderDto = parseOrder(value); // Convert the message to OrderDto object
                    if (key.equals("flipkart.car.order")) {
                        aggregate.carOrderCount++;
                        aggregate.carTotalTransactionAmount += orderDto.getPrice();
                    } else if (key.equals("flipkart.mobile.order")) {
                        aggregate.mobileOrderCount++;
                        aggregate.mobileTotalTransactionAmount += orderDto.getPrice();
                    } else if (key.equals("flipkart.book.order")) {
                        aggregate.bookOrderCount++;
                        aggregate.bookTotalTransactionAmount += orderDto.getPrice();
                    }
                    return aggregate;
                },
                Materialized.with(Serdes.String(), OrderAggregateSerde())
            );

        // Send aggregated result to ReportTopic
        aggregateTable.toStream()
                .to("ReportTopic", Produced.with(Serdes.String(), OrderAggregateSerde()));

        // Build and start the Kafka Streams application
        KafkaStreams streams = new KafkaStreams(builder.build(), props);
        streams.start();

        Runtime.getRuntime().addShutdownHook(new Thread(streams::close));
    }

    // Initializer for the aggregate (starting with 0 counts and totals)
    private static OrderAggregate newOrderAggregate() {
        return new OrderAggregate(0, 0, 0, 0, 0, 0);
    }

    // Function to parse incoming order message into DTO
    private static OrderDto parseOrder(String message) {
        // Assume message is a JSON string, convert it to OrderDto object
        // This could vary based on your message structure
        return new OrderDto(); // Simplified for this example
    }
}
// Aggregated values for the orders
public class OrderAggregate {
    public int carOrderCount;
    public long carTotalTransactionAmount;
    public int mobileOrderCount;
    public long mobileTotalTransactionAmount;
    public int bookOrderCount;
    public long bookTotalTransactionAmount;

    public OrderAggregate(int carOrderCount, long carTotalTransactionAmount, int mobileOrderCount,
                          long mobileTotalTransactionAmount, int bookOrderCount, long bookTotalTransactionAmount) {
        this.carOrderCount = carOrderCount;
        this.carTotalTransactionAmount = carTotalTransactionAmount;
        this.mobileOrderCount = mobileOrderCount;
        this.mobileTotalTransactionAmount = mobileTotalTransactionAmount;
        this.bookOrderCount = bookOrderCount;
        this.bookTotalTransactionAmount = bookTotalTransactionAmount;
    }

    @Override
    public String toString() {
        return "Car Orders: " + carOrderCount + " | Car Total: " + carTotalTransactionAmount +
               ", Mobile Orders: " + mobileOrderCount + " | Mobile Total: " + mobileTotalTransactionAmount +
               ", Book Orders: " + bookOrderCount + " | Book Total: " + bookTotalTransactionAmount;
    }
}

// DTO for the Order
public class OrderDto {
    private int id;
    private String model;
    private long price;

    public OrderDto() {}

    public OrderDto(int id, String model, long price) {
        this.id = id;
        this.model = model;
        this.price = price;
    }

    public long getPrice() {
        return price;
    }

    // Getters and setters...
}

---------------------------------------
import com.fasterxml.jackson.databind.ObjectMapper;
import org.apache.kafka.common.serialization.Serializer;

import java.util.Map;

public class OrderAggregateSerializer implements Serializer<OrderAggregate> {
    private final ObjectMapper objectMapper = new ObjectMapper();

    @Override
    public void configure(Map<String, ?> configs, boolean isKey) {
        // No configuration needed
    }

    @Override
    public byte[] serialize(String topic, OrderAggregate data) {
        try {
            return objectMapper.writeValueAsBytes(data);
        } catch (Exception e) {
            throw new RuntimeException("Error serializing OrderAggregate", e);
        }
    }

    @Override
    public void close() {
        // Nothing to do
    }
}
----------------------------------
import com.fasterxml.jackson.databind.ObjectMapper;
import org.apache.kafka.common.serialization.Deserializer;

import java.util.Map;

public class OrderAggregateDeserializer implements Deserializer<OrderAggregate> {
    private final ObjectMapper objectMapper = new ObjectMapper();

    @Override
    public void configure(Map<String, ?> configs, boolean isKey) {
        // No configuration needed
    }

    @Override
    public OrderAggregate deserialize(String topic, byte[] data) {
        try {
            return objectMapper.readValue(data, OrderAggregate.class);
        } catch (Exception e) {
            throw new RuntimeException("Error deserializing OrderAggregate", e);
        }
    }

    @Override
    public void close() {
        // Nothing to do
    }
}
--------------------------
import org.apache.kafka.common.serialization.Serde;
import org.apache.kafka.common.serialization.Serdes;

public class OrderAggregateSerde implements Serde<OrderAggregate> {

    private final OrderAggregateSerializer serializer = new OrderAggregateSerializer();
    private final OrderAggregateDeserializer deserializer = new OrderAggregateDeserializer();

    @Override
    public Serializer<OrderAggregate> serializer() {
        return serializer;
    }

    @Override
    public Deserializer<OrderAggregate> deserializer() {
        return deserializer;
    }

    @Override
    public void close() {
        // Nothing to do
    }
}
------------------------------
KTable<String, OrderAggregate> aggregateTable = orderStream
    .groupByKey()
    .aggregate(
        OrderAggregator::newOrderAggregate,
        (key, value, aggregate) -> {
            OrderDto orderDto = parseOrder(value);
            if (key.equals("flipkart.car.order")) {
                aggregate.carOrderCount++;
                aggregate.carTotalTransactionAmount += orderDto.getPrice();
            } else if (key.equals("flipkart.mobile.order")) {
                aggregate.mobileOrderCount++;
                aggregate.mobileTotalTransactionAmount += orderDto.getPrice();
            } else if (key.equals("flipkart.book.order")) {
                aggregate.bookOrderCount++;
                aggregate.bookTotalTransactionAmount += orderDto.getPrice();
            }
            return aggregate;
        },
        Materialized.with(Serdes.String(), new OrderAggregateSerde())
    );
